{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR Project Final",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOv4MtGyW2gboC+ofDVCAlc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rhevanth/Hacktoberfest-2k17/blob/master/IR_Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h547-q33tYpk"
      },
      "source": [
        "# Histogram of Oriented Gradients (HOG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh7Tnd8LttvX"
      },
      "source": [
        "#imports\n",
        "#import evaluator file\n",
        "from evaluate import evaluate_class\n",
        "\n",
        "#import database\n",
        "from DB import Database\n",
        "\n",
        "#import HOG model\n",
        "from skimage.feature import hog\n",
        "\n",
        "#import color model\n",
        "from skimage import color\n",
        "\n",
        "#import oyhrt necessary modules\n",
        "from six.moves import cPickle\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aNHpElSthww"
      },
      "source": [
        "#define and initialize HOG Metrics\n",
        "n_bin    = 10\n",
        "n_slice  = 6\n",
        "n_orient = 8\n",
        "p_p_c    = (2, 2)\n",
        "c_p_b    = (1, 1)\n",
        "h_type   = 'region'\n",
        "d_type   = 'd1'\n",
        "\n",
        "depth    = 5\n",
        "# cache directory\n",
        "cache_dir = 'cache'\n",
        "if not os.path.exists(cache_dir):\n",
        "  os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "class HOG(object):\n",
        "\n",
        "  def histogram(self, input, n_bin=n_bin, type=h_type, n_slice=n_slice, normalize=True):\n",
        "    if isinstance(input, np.ndarray): \n",
        "      img = input.copy()\n",
        "    else:\n",
        "      img = scipy.misc.imread(input, mode='RGB')\n",
        "    height, width, channel = img.shape\n",
        "  \n",
        "    if type == 'global':\n",
        "      hist = self._HOG(img, n_bin)\n",
        "  \n",
        "    elif type == 'region':\n",
        "      hist = np.zeros((n_slice, n_slice, n_bin))\n",
        "      h_silce = np.around(np.linspace(0, height, n_slice+1, endpoint=True)).astype(int)\n",
        "      w_slice = np.around(np.linspace(0, width, n_slice+1, endpoint=True)).astype(int)\n",
        "  \n",
        "      for hs in range(len(h_silce)-1):\n",
        "        for ws in range(len(w_slice)-1):\n",
        "          img_r = img[h_silce[hs]:h_silce[hs+1], w_slice[ws]:w_slice[ws+1]]  \n",
        "          hist[hs][ws] = self._HOG(img_r, n_bin)\n",
        "  \n",
        "    if normalize:\n",
        "      hist /= np.sum(hist)\n",
        "  \n",
        "    return hist.flatten()\n",
        "\n",
        "  def _HOG(self, img, n_bin, normalize=True):\n",
        "    image = color.rgb2gray(img)\n",
        "    fd = hog(image, orientations=n_orient, pixels_per_cell=p_p_c, cells_per_block=c_p_b)\n",
        "    bins = np.linspace(0, np.max(fd), n_bin+1, endpoint=True)\n",
        "    hist, _ = np.histogram(fd, bins=bins)\n",
        "  \n",
        "    if normalize:\n",
        "      hist = np.array(hist) / np.sum(hist)\n",
        "  \n",
        "    return hist\n",
        "\n",
        "  def make_samples(self, db, verbose=True):\n",
        "    if h_type == 'global':\n",
        "      sample_cache = \"HOG-{}-n_bin{}-n_orient{}-ppc{}-cpb{}\".format(h_type, n_bin, n_orient, p_p_c, c_p_b)\n",
        "    elif h_type == 'region':\n",
        "      sample_cache = \"HOG-{}-n_bin{}-n_slice{}-n_orient{}-ppc{}-cpb{}\".format(h_type, n_bin, n_slice, n_orient, p_p_c, c_p_b)\n",
        "  \n",
        "    try:\n",
        "      samples = cPickle.load(open(os.path.join(cache_dir, sample_cache), \"rb\", True))\n",
        "      for sample in samples:\n",
        "        sample['hist'] /= np.sum(sample['hist'])  # normalize\n",
        "      if verbose:\n",
        "        print(\"Using cache..., config=%s, distance=%s, depth=%s\" % (sample_cache, d_type, depth))\n",
        "    except:\n",
        "      if verbose:\n",
        "        print(\"Counting histogram..., config=%s, distance=%s, depth=%s\" % (sample_cache, d_type, depth))\n",
        "\n",
        "      samples = []\n",
        "      data = db.get_data()\n",
        "      for d in data.itertuples():\n",
        "        d_img, d_cls = getattr(d, \"img\"), getattr(d, \"cls\")\n",
        "        d_hist = self.histogram(d_img, type=h_type, n_slice=n_slice)\n",
        "        samples.append({'img':  d_img, 'cls':  d_cls, 'hist': d_hist})\n",
        "      cPickle.dump(samples, open(os.path.join(cache_dir, sample_cache), \"wb\", True))\n",
        "\n",
        "    return samples\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofa-6hHJuHoo"
      },
      "source": [
        "def hog_function():\n",
        "  db = Database()\n",
        "  APs = evaluate_class(db, f_class=HOG, d_type=d_type, depth=depth)\n",
        "  cls_MAPs = []\n",
        "  for cls, cls_APs in APs.items():\n",
        "    MAP = np.mean(cls_APs)\n",
        "    print(\"Class {}, MAP {}\".format(cls, MAP))\n",
        "    cls_MAPs.append(MAP)\n",
        "  print(\"MMAP\", np.mean(cls_MAPs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i_sruaouIua"
      },
      "source": [
        "# DAISY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwXw4FoCu0P4"
      },
      "source": [
        "#imports\n",
        "from __future__ import print_function\n",
        "\n",
        "#import evaluator file\n",
        "from evaluate import evaluate_class\n",
        "\n",
        "#import database\n",
        "from DB import Database\n",
        "\n",
        "#import daisy model\n",
        "from skimage.feature import daisy\n",
        "\n",
        "#import color model\n",
        "from skimage import color\n",
        "\n",
        "#import other required libraries\n",
        "from six.moves import cPickle\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import math\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6LU14KauSIr"
      },
      "source": [
        "#define and initialize Daisy Metrics\n",
        "n_slice    = 2\n",
        "n_orient   = 8\n",
        "step       = 10\n",
        "radius     = 30\n",
        "rings      = 2\n",
        "histograms = 6\n",
        "h_type     = 'region'\n",
        "d_type     = 'd1'\n",
        "depth      = 5\n",
        "\n",
        "R = (rings * histograms + 1) * n_orient\n",
        "\n",
        "# cache directory\n",
        "cache_dir = 'cache'\n",
        "if not os.path.exists(cache_dir):\n",
        "  os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "class Daisy(object):\n",
        "\n",
        "  def histogram(self, input, type=h_type, n_slice=n_slice, normalize=True):\n",
        "    if isinstance(input, np.ndarray): \n",
        "      img = input.copy()\n",
        "    else:\n",
        "      img = scipy.misc.imread(input, mode='RGB')\n",
        "    height, width, channel = img.shape\n",
        "  \n",
        "    P = math.ceil((height - radius*2) / step) \n",
        "    Q = math.ceil((width - radius*2) / step)\n",
        "    assert P > 0 and Q > 0, \"input image size need to pass this check\"\n",
        "\n",
        "    if type == 'global':\n",
        "      hist = self._daisy(img)\n",
        "  \n",
        "    elif type == 'region':\n",
        "      hist = np.zeros((n_slice, n_slice, R))\n",
        "      h_silce = np.around(np.linspace(0, height, n_slice+1, endpoint=True)).astype(int)\n",
        "      w_slice = np.around(np.linspace(0, width, n_slice+1, endpoint=True)).astype(int)\n",
        "  \n",
        "      for hs in range(len(h_silce)-1):\n",
        "        for ws in range(len(w_slice)-1):\n",
        "          img_r = img[h_silce[hs]:h_silce[hs+1], w_slice[ws]:w_slice[ws+1]]  # slice image to regions\n",
        "          hist[hs][ws] = self._daisy(img_r)\n",
        "  \n",
        "    if normalize:\n",
        "      hist /= np.sum(hist)\n",
        "  \n",
        "    return hist.flatten()\n",
        "  \n",
        "  \n",
        "  def _daisy(self, img, normalize=True):\n",
        "    image = color.rgb2gray(img)\n",
        "    descs = daisy(image, step=step, radius=radius, rings=rings, histograms=histograms, orientations=n_orient)\n",
        "    descs = descs.reshape(-1, R)  # shape=(N, R)\n",
        "    hist  = np.mean(descs, axis=0)  # shape=(R,)\n",
        "  \n",
        "    if normalize:\n",
        "      hist = np.array(hist) / np.sum(hist)\n",
        "  \n",
        "    return hist\n",
        "  \n",
        "  \n",
        "  def make_samples(self, db, verbose=True):\n",
        "    if h_type == 'global':\n",
        "      sample_cache = \"daisy-{}-n_orient{}-step{}-radius{}-rings{}-histograms{}\".format(h_type, n_orient, step, radius, rings, histograms)\n",
        "    elif h_type == 'region':\n",
        "      sample_cache = \"daisy-{}-n_slice{}-n_orient{}-step{}-radius{}-rings{}-histograms{}\".format(h_type, n_slice, n_orient, step, radius, rings, histograms)\n",
        "  \n",
        "    try:\n",
        "      samples = cPickle.load(open(os.path.join(cache_dir, sample_cache), \"rb\", True))\n",
        "      for sample in samples:\n",
        "        sample['hist'] /= np.sum(sample['hist'])  # normalize\n",
        "      if verbose:\n",
        "        print(\"Using cache..., config=%s, distance=%s, depth=%s\" % (sample_cache, d_type, depth))\n",
        "    except:\n",
        "      if verbose:\n",
        "        print(\"Counting histogram..., config=%s, distance=%s, depth=%s\" % (sample_cache, d_type, depth))\n",
        "  \n",
        "      samples = []\n",
        "      data = db.get_data()\n",
        "      for d in data.itertuples():\n",
        "        d_img, d_cls = getattr(d, \"img\"), getattr(d, \"cls\")\n",
        "        d_hist = self.histogram(d_img, type=h_type, n_slice=n_slice)\n",
        "        samples.append({\n",
        "                        'img':  d_img, \n",
        "                        'cls':  d_cls, \n",
        "                        'hist': d_hist\n",
        "                      })\n",
        "      cPickle.dump(samples, open(os.path.join(cache_dir, sample_cache), \"wb\", True))\n",
        "  \n",
        "    return samples\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13MsLlP_vETp"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  db = Database()\n",
        "\n",
        "  # evaluate database\n",
        "  APs = evaluate_class(db, f_class=Daisy, d_type=d_type, depth=depth)\n",
        "  cls_MAPs = []\n",
        "  for cls, cls_APs in APs.items():\n",
        "    MAP = np.mean(cls_APs)\n",
        "    print(\"Class {}, MAP {}\".format(cls, MAP))\n",
        "    cls_MAPs.append(MAP)\n",
        "  print(\"MMAP\", np.mean(cls_MAPs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwVrPbvPvYcu"
      },
      "source": [
        "# VGG-19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90v0xmQ_vf4v"
      },
      "source": [
        "#import torch libraries for VGG\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import VGG\n",
        "\n",
        "#import other necessary modules\n",
        "from six.moves import cPickle\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import os\n",
        "\n",
        "#import evaluator file\n",
        "from evaluate import evaluate_class\n",
        "\n",
        "#import database\n",
        "from DB import Database\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPKtshMgvbJq"
      },
      "source": [
        "#define and initialize VGG Metrics\n",
        "VGG_model  = 'vgg19'  \n",
        "pick_layer = 'avg'    \n",
        "d_type     = 'd1'     \n",
        "\n",
        "depth      = 5      \n",
        "use_gpu = torch.cuda.is_available()\n",
        "means = np.array([103.939, 116.779, 123.68]) / 255. \n",
        "\n",
        "# cache directory\n",
        "cache_dir = 'cache'\n",
        "if not os.path.exists(cache_dir):\n",
        "  os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "class VGGNet(VGG):\n",
        "  def __init__(self, pretrained=True, model='vgg16', requires_grad=False, remove_fc=False, show_params=False):\n",
        "    super().__init__(make_layers(cfg[model]))\n",
        "    self.ranges = ranges[model]\n",
        "    self.fc_ranges = ((0, 2), (2, 5), (5, 7))\n",
        "\n",
        "    if pretrained:\n",
        "      exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
        "\n",
        "    if not requires_grad:\n",
        "      for param in super().parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    if remove_fc:  \n",
        "      del self.classifier\n",
        "\n",
        "    if show_params:\n",
        "      for name, param in self.named_parameters():\n",
        "        print(name, param.size())\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = {}\n",
        "\n",
        "    x = self.features(x)\n",
        "\n",
        "    avg_pool = torch.nn.AvgPool2d((x.size(-2), x.size(-1)), stride=(x.size(-2), x.size(-1)), padding=0, ceil_mode=False, count_include_pad=True)\n",
        "    avg = avg_pool(x) \n",
        "    avg = avg.view(avg.size(0), -1)  \n",
        "    output['avg'] = avg\n",
        "\n",
        "    x = x.view(x.size(0), -1)  \n",
        "    dims = x.size(1)\n",
        "    if dims >= 25088:\n",
        "      x = x[:, :25088]\n",
        "      for idx in range(len(self.fc_ranges)):\n",
        "        for layer in range(self.fc_ranges[idx][0], self.fc_ranges[idx][1]):\n",
        "          x = self.classifier[layer](x)\n",
        "        output[\"fc%d\"%(idx+1)] = x\n",
        "    else:\n",
        "      w = self.classifier[0].weight[:, :dims]\n",
        "      b = self.classifier[0].bias\n",
        "      x = torch.matmul(x, w.t()) + b\n",
        "      x = self.classifier[1](x)\n",
        "      output[\"fc1\"] = x\n",
        "      for idx in range(1, len(self.fc_ranges)):\n",
        "        for layer in range(self.fc_ranges[idx][0], self.fc_ranges[idx][1]):\n",
        "          x = self.classifier[layer](x)\n",
        "        output[\"fc%d\"%(idx+1)] = x\n",
        "\n",
        "    return output\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM00ViFVw5wR"
      },
      "source": [
        "ranges = {\n",
        "  'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
        "  'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
        "  'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
        "  'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
        "}\n",
        "\n",
        "cfg = {\n",
        "  'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "  'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "  'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "  'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "  layers = []\n",
        "  in_channels = 3\n",
        "  for v in cfg:\n",
        "    if v == 'M':\n",
        "      layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "    else:\n",
        "      conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "      if batch_norm:\n",
        "        layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "      else:\n",
        "        layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "      in_channels = v\n",
        "  return nn.Sequential(*layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP-k60udvwAY"
      },
      "source": [
        "class VGGNetFeat(object):\n",
        "\n",
        "  def make_samples(self, db, verbose=True):\n",
        "    sample_cache = '{}-{}'.format(VGG_model, pick_layer)\n",
        "  \n",
        "    try:\n",
        "      samples = cPickle.load(open(os.path.join(cache_dir, sample_cache), \"rb\", True))\n",
        "      for sample in samples:\n",
        "        sample['hist'] /= np.sum(sample['hist'])  \n",
        "      cPickle.dump(samples, open(os.path.join(cache_dir, sample_cache), \"wb\", True))\n",
        "      if verbose:\n",
        "        print(\"Using cache..., config=%s, distance=%s, depth=%s\" % (sample_cache, d_type, depth))\n",
        "    except:\n",
        "      if verbose:\n",
        "        print(\"Counting histogram..., config=%s, distance=%s, depth=%s\" % (sample_cache, d_type, depth))\n",
        "  \n",
        "      vgg_model = VGGNet(requires_grad=False, model=VGG_model)\n",
        "      vgg_model.eval()\n",
        "      if use_gpu:\n",
        "        vgg_model = vgg_model.cuda()\n",
        "      samples = []\n",
        "      data = db.get_data()\n",
        "      for d in data.itertuples():\n",
        "        d_img, d_cls = getattr(d, \"img\"), getattr(d, \"cls\")\n",
        "        img = scipy.misc.imread(d_img, mode=\"RGB\")\n",
        "        img = img[:, :, ::-1]  \n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= means[0] \n",
        "        img[1] -= means[1] \n",
        "        img[2] -= means[2] \n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        try:\n",
        "          if use_gpu:\n",
        "            inputs = torch.autograd.Variable(torch.from_numpy(img).cuda().float())\n",
        "          else:\n",
        "            inputs = torch.autograd.Variable(torch.from_numpy(img).float())\n",
        "          d_hist = vgg_model(inputs)[pick_layer]\n",
        "          d_hist = np.sum(d_hist.data.cpu().numpy(), axis=0)\n",
        "          d_hist /= np.sum(d_hist)  \n",
        "          samples.append({\n",
        "                          'img':  d_img, \n",
        "                          'cls':  d_cls, \n",
        "                          'hist': d_hist\n",
        "                         })\n",
        "        except:\n",
        "          pass\n",
        "      cPickle.dump(samples, open(os.path.join(cache_dir, sample_cache), \"wb\", True))\n",
        "  \n",
        "    return samples\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkhQKeeAv0ZM"
      },
      "source": [
        "def vgg_function():\n",
        "  \n",
        "  db = Database()\n",
        "  APs = evaluate_class(db, f_class=VGGNetFeat, d_type=d_type, depth=depth)\n",
        "  cls_MAPs = []\n",
        "  for cls, cls_APs in APs.items():\n",
        "    MAP = np.mean(cls_APs)\n",
        "    print(\"Class {}, MAP {}\".format(cls, MAP))\n",
        "    cls_MAPs.append(MAP)\n",
        "  print(\"MMAP\", np.mean(cls_MAPs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1SnUOPfxrhj"
      },
      "source": [
        "# ResNet-152"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO7JtHcXxuoL"
      },
      "source": [
        "#imports\n",
        "\n",
        "#import torch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, ResNet\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "#import other necessary modules\n",
        "from six.moves import cPickle\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import os\n",
        "\n",
        "#import evaluator file\n",
        "from evaluate import evaluate_class\n",
        "\n",
        "#import database\n",
        "from DB import Database\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAuyd2rPz-BH"
      },
      "source": [
        "#define and initialize ResNet Metrics\n",
        "RES_model  = 'resnet152' \n",
        "pick_layer = 'avg'  \n",
        "d_type     = 'd1'\n",
        "\n",
        "depth = 5 \n",
        "use_gpu = torch.cuda.is_available()\n",
        "means = np.array([103.939, 116.779, 123.68]) / 255.\n",
        "# cache directory\n",
        "cache_dir = 'cache'\n",
        "if not os.path.exists(cache_dir):\n",
        "  os.makedirs(cache_dir)\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0-qMifvz7Gz"
      },
      "source": [
        "class ResidualNet(ResNet):\n",
        "  def __init__(self, model=RES_model, pretrained=True):\n",
        "    if model == \"resnet18\":\n",
        "        super().__init__(BasicBlock, [2, 2, 2, 2], 1000)\n",
        "        if pretrained:\n",
        "            self.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    elif model == \"resnet34\":\n",
        "        super().__init__(BasicBlock, [3, 4, 6, 3], 1000)\n",
        "        if pretrained:\n",
        "            self.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    elif model == \"resnet50\":\n",
        "        super().__init__(Bottleneck, [3, 4, 6, 3], 1000)\n",
        "        if pretrained:\n",
        "            self.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    elif model == \"resnet101\":\n",
        "        super().__init__(Bottleneck, [3, 4, 23, 3], 1000)\n",
        "        if pretrained:\n",
        "            self.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    elif model == \"resnet152\":\n",
        "        super().__init__(Bottleneck, [3, 8, 36, 3], 1000)\n",
        "        if pretrained:\n",
        "            self.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)  \n",
        "    max_pool = torch.nn.MaxPool2d((x.size(-2),x.size(-1)), stride=(x.size(-2),x.size(-1)), padding=0, ceil_mode=False)\n",
        "    Max = max_pool(x)  \n",
        "    Max = Max.view(Max.size(0), -1) \n",
        "    avg_pool = torch.nn.AvgPool2d((x.size(-2),x.size(-1)), stride=(x.size(-2),x.size(-1)), padding=0, ceil_mode=False, count_include_pad=True)\n",
        "    avg = avg_pool(x) \n",
        "    avg = avg.view(avg.size(0), -1)  \n",
        "    fc = self.fc(avg)\n",
        "    output = {\n",
        "        'max': Max,\n",
        "        'avg': avg,\n",
        "        'fc' : fc\n",
        "    }\n",
        "    return output\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slk1RI4Az3rI"
      },
      "source": [
        "class ResNetFeat(object):\n",
        "\n",
        "  def make_samples(self, db, verbose=True):\n",
        "    sample_cache = '{}-{}'.format(RES_model, pick_layer)\n",
        "  \n",
        "    try:\n",
        "      samples = cPickle.load(open(os.path.join(cache_dir, sample_cache), \"rb\", True))\n",
        "      for sample in samples:\n",
        "        sample['hist'] /= np.sum(sample['hist']) \n",
        "\n",
        "      res_model = ResidualNet(model=RES_model)\n",
        "      res_model.eval()\n",
        "      if use_gpu:\n",
        "        res_model = res_model.cuda()\n",
        "      samples = []\n",
        "      data = db.get_data()\n",
        "      for d in data.itertuples():\n",
        "        d_img, d_cls = getattr(d, \"img\"), getattr(d, \"cls\")\n",
        "        img = scipy.misc.imread(d_img, mode=\"RGB\")\n",
        "        img = img[:, :, ::-1]\n",
        "        img = np.transpose(img, (2, 0, 1)) / 255.\n",
        "        img[0] -= means[0]  \n",
        "        img[1] -= means[1]\n",
        "        img[2] -= means[2]\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        try:\n",
        "          if use_gpu:\n",
        "            inputs = torch.autograd.Variable(torch.from_numpy(img).cuda().float())\n",
        "          else:\n",
        "            inputs = torch.autograd.Variable(torch.from_numpy(img).float())\n",
        "          d_hist = res_model(inputs)[pick_layer]\n",
        "          d_hist = d_hist.data.cpu().numpy().flatten()\n",
        "          d_hist /= np.sum(d_hist)\n",
        "          samples.append({\n",
        "                          'img':  d_img, \n",
        "                          'cls':  d_cls, \n",
        "                          'hist': d_hist\n",
        "                         })\n",
        "        except:\n",
        "          pass\n",
        "      cPickle.dump(samples, open(os.path.join(cache_dir, sample_cache), \"wb\", True))\n",
        "  \n",
        "    return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfY6IiA1zzS6"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  db = Database()\n",
        "  APs = evaluate_class(db, f_class=ResNetFeat, d_type=d_type, depth=depth)\n",
        "  cls_MAPs = []\n",
        "  for cls, cls_APs in APs.items():\n",
        "    MAP = np.mean(cls_APs)\n",
        "    print(\"Class {}, MAP {}\".format(cls, MAP))\n",
        "    cls_MAPs.append(MAP)\n",
        "  print(\"MMAP\", np.mean(cls_MAPs))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}